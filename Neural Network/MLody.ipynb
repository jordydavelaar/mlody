{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0474fd9e-a069-48c9-b906-c856ee09181e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set enviroment\n",
    "\n",
    "import os, sys\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import importlib; importlib.reload(K)\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        importlib.reload(K)\n",
    "\n",
    "set_keras_backend(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741c2a86-d114-49a5-98a1-da96f1bd7abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dependencies for plotting \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "font = {'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf1b003-ef88-4f20-bcf6-38cdaefcd5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seed the pseudorandom number generator\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "# seed random number generator\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b164b223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import Tensorflow \n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input,  LeakyReLU, Activation\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import tensorflow.keras.losses\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import saving\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, LayerNormalization\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.initializers import GlorotUniform, LecunNormal\n",
    "from tensorflow.math import square, sqrt\n",
    "from tensorflow.math import reduce_mean as mean\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5ca32a-80a5-4e9e-bb46-ac0f843f33aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "nu, theta_e, theta_b, jI, aI, jI_fit, aI_fit, jQ, aQ, rQ, jQ_fit, aQ_fit, rQ_fit, jV,aV, rV, jV_fit, aV_fit, rV_fit= np.loadtxt(\"data_pol_v2.txt\", unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccdbc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data massaging\n",
    "jQ=-jQ\n",
    "aQ=-aQ\n",
    "\n",
    "jQ_fit=-jQ_fit\n",
    "aQ_fit=-aQ_fit\n",
    "\n",
    "jV = jV /(theta_b)\n",
    "aV = aV /(theta_b)\n",
    "jV_fit = jV/theta_b\n",
    "aV_fit=aV_fit/theta_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ec4c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to check some trivial bounds, we dont want out of bound numbers or zero numbers, this means the coefficients are very small anyway\n",
    "def check_data(use,absol=False):\n",
    "    global nu, theta_e, theta_b, jI, aI, jI_fit, aI_fit, jQ, aQ, rQ, jQ_fit, aQ_fit, rQ_fit, jV,aV, rV, jV_fit, aV_fit, rV_fit\n",
    "    if(absol):\n",
    "        use=np.abs(use)\n",
    "    nu=nu[use>1e-299]\n",
    "    theta_e=theta_e[use>1e-299]\n",
    "    theta_b=theta_b[use>1e-299]\n",
    "    \n",
    "    jI=jI[use>1e-299]\n",
    "    jI_fit=jI_fit[use>1e-299]\n",
    "\n",
    "    aI=aI[use>1e-299]\n",
    "    aI_fit=aI_fit[use>1e-299]\n",
    "\n",
    "    jQ=jQ[use>1e-299]\n",
    "    jQ_fit=jQ_fit[use>1e-299]\n",
    "\n",
    "    aQ=aQ[use>1e-299]\n",
    "    aQ_fit=aQ_fit[use>1e-299]\n",
    "\n",
    "    rQ=rQ[use>1e-299]\n",
    "    rQ_fit=rQ_fit[use>1e-299]\n",
    "\n",
    "    jV=jV[use>1e-299]\n",
    "    jV_fit=jV_fit[use>1e-299]\n",
    "\n",
    "    aV=aV[use>1e-299]\n",
    "    aV_fit=aV_fit[use>1e-299]\n",
    "\n",
    "    rV=rV[use>1e-299]\n",
    "    rV_fit=rV_fit[use>1e-299]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc8ff6-6f54-401f-8227-8704afd00128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run function on all coefficients and check the shape to see how much changed\n",
    "print(jI.shape)\n",
    "\n",
    "check_data(jI)\n",
    "check_data(aI)\n",
    "\n",
    "check_data(jQ)\n",
    "check_data(aQ)\n",
    "\n",
    "check_data(jV)\n",
    "check_data(aV)\n",
    "\n",
    "print(jI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6374ce6-6609-4146-a028-6f1578767e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same for rhoQ and rhoV, but keep an eye on that these are not positive number, so need to take the absolute value\n",
    "check_data(rQ,absol=True)\n",
    "\n",
    "check_data(rV,absol=True)\n",
    "print(jI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089c9e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Construct an input vector X and output vector y\n",
    "X = np.zeros(shape=(3,len(nu)))\n",
    "y = np.zeros(shape=(8,len(jI)))\n",
    "\n",
    "xmin = np.zeros(shape=(3))\n",
    "xmax = np.zeros(shape=(3))\n",
    "ymin = np.zeros(shape=(8))\n",
    "ymax = np.zeros(shape=(8)) \n",
    "\n",
    "#in general we recenter and renormalize all variables so that they have a mean of zero and a range of +/- unity\n",
    "\n",
    "#first input data\n",
    "X[0] = np.log10(nu)- 0.5*(np.max(np.log10(nu)) + np.min(np.log10(nu)))\n",
    "xmin[0]=0.5*(np.max(np.log10(nu)) + np.min(np.log10(nu)))\n",
    "xmax[0]=np.max(X[0])\n",
    "X[0]/=np.max(X[0])\n",
    "\n",
    "print(\"nu min: \", xmin[0], \"max: \", xmax[0])\n",
    "print(\"X0 min: \", np.min(X[0]), \"max: \", np.max(X[0]))\n",
    "\n",
    "X[1] = np.log10(theta_e)-0.5*(np.max(np.log10(theta_e)) + np.min(np.log10(theta_e)))\n",
    "xmin[1]=0.5*(np.max(np.log10(theta_e)) + np.min(np.log10(theta_e)))\n",
    "xmax[1]=np.max(X[1])\n",
    "X[1]/=np.max(X[1])\n",
    "\n",
    "print(\"theta min: \", xmin[1], \"max: \", xmax[1])\n",
    "print(\"X1 min: \", np.min(X[1]), \"max: \", np.max(X[1]))\n",
    "\n",
    "xmin[2]=0.5*(np.min(theta_b)+np.max(theta_b))\n",
    "\n",
    "X[2]=theta_b-xmin[2]\n",
    "xmax[2]=np.max(X[2])\n",
    "X[2]/=np.max(X[2])\n",
    "\n",
    "print(\"theta_b min: \", xmin[2], \"max: \", xmax[2])\n",
    "print(\"X2 min: \", np.min(X[2]), \"max: \", np.max(X[2]))\n",
    "\n",
    "#Output data\n",
    "ymin[0]=0.5*(np.max(np.log10(jI)) + np.min(np.log10(jI)))\n",
    "y[0] = np.log10(jI) - ymin[0]\n",
    "ymax[0]=np.max(y[0])\n",
    "y[0] /=np.max(y[0])\n",
    "\n",
    "ymin[1]=0.5*(np.max(np.log10(aI)) + np.min(np.log10(aI)))\n",
    "y[1] = np.log10(aI) - ymin[1]\n",
    "ymax[1]=np.max(y[1])\n",
    "y[1] /=np.max(y[1])\n",
    "\n",
    "ymin[2]=0.5*(np.max(np.log10(jQ)) + np.min(np.log10(jQ)))\n",
    "y[2] = np.log10(jQ) - ymin[2]\n",
    "ymax[2]=np.max(y[2])\n",
    "y[2] /=np.max(y[2])\n",
    "\n",
    "ymin[3]=0.5*(np.max(np.log10(aQ)) + np.min(np.log10(aQ)))\n",
    "y[3] = np.log10(aQ) - ymin[3]\n",
    "ymax[3]=np.max(y[3])\n",
    "y[3] /=np.max(y[3])\n",
    "\n",
    "y[4] =  np.sign(rQ)*np.fabs(rQ)**0.25\n",
    "ymin[4]  = 0.5*(np.max(y[4])+np.min(y[4]))\n",
    "y[4] = y[4] - ymin[4]\n",
    "ymax[4]=np.max(y[4])\n",
    "y[4] /=np.max(y[4])\n",
    "\n",
    "ymin[5]=0.5*(np.max(np.log10(jV)) + np.min(np.log10(jV)))\n",
    "y[5] = np.log10(jV) - ymin[5]\n",
    "ymax[5]=np.max(y[5])\n",
    "y[5] /=np.max(y[5])\n",
    "\n",
    "ymin[6]=0.5*(np.max(np.log10(aV)) + np.min(np.log10(aV)))\n",
    "y[6] = np.log10(aV)- ymin[6]\n",
    "ymax[6]=np.max(y[6])\n",
    "y[6] /=np.max(y[6])\n",
    "\n",
    "y[7] = np.sign(rV)*np.fabs(rV)**0.25\n",
    "ymin[7]  = 0.5*(np.max(y[7])+np.min(y[7]))\n",
    "y[7] = y[7] - ymin[7]\n",
    "ymax[7]=np.max(y[7])\n",
    "y[7] /=np.max(y[7])\n",
    "\n",
    "print(\"Stokes I\")\n",
    "print(\"min:\", ymin[0],\"max\", ymax[0])\n",
    "print(\"min:\", ymin[1],\"max\", ymax[1])\n",
    "\n",
    "print(\"Stokes Q\")\n",
    "print(\"min:\", ymin[2],\"max\", ymax[2])\n",
    "print(\"min:\", ymin[3],\"max\", ymax[3])\n",
    "print(\"min:\", ymin[4], \"max\", ymax[4])\n",
    "\n",
    "print(\"\\nStokes V\")\n",
    "print(\"min:\", ymin[5], \"max\", ymax[5])\n",
    "print(\"min:\", ymin[6], \"max\", ymax[6])\n",
    "print(\"min:\", ymin[7], \"max\", ymax[7])\n",
    "\n",
    "print(\"Stokes I\")\n",
    "print(\"min:\",np.min(y[0]),\"max:\",np.max(y[0]))\n",
    "print(\"min:\",np.min(y[1]),\"max:\",np.max(y[1]))\n",
    "\n",
    "print(\"Stokes Q\")\n",
    "print(\"min:\",np.min(y[2]),\"max:\",np.max(y[2]))\n",
    "print(\"min:\",np.min(y[3]),\"max:\",np.max(y[3]))\n",
    "print(\"min:\",np.min(y[4]),\"max:\",np.max(y[4]))\n",
    "\n",
    "print(\"\\nStokes V\")\n",
    "print(\"min:\",np.min(y[5]),\"max:\",np.max(y[5]))\n",
    "print(\"min:\",np.min(y[6]),\"max:\",np.max(y[6]))\n",
    "print(\"min:\",np.min(y[7]),\"max:\",np.max(y[7]))\n",
    "\n",
    "X=X.transpose()\n",
    "y=y.transpose()\n",
    "print(X.shape,y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff7339-a489-4ded-99e5-54586e898e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the recentering and normalization coefficients, we will need them if want to transfer them back.\n",
    "xrange = [xmin,xmax]\n",
    "yrange = [ymin,ymax]\n",
    "\n",
    "out = np.concatenate((xrange, yrange),axis=1)\n",
    "print(np.shape(out))\n",
    "out = np.transpose(out)\n",
    "np.savetxt(\"minmax.txt\",out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24683679-2d4c-4915-95fb-808b82573d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#time to split training data!  we use 80/20 split between training and validation and keep 20,000 \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                   y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=12412412)\n",
    "\n",
    " X_val, X_test, y_val, y_test = train_test_split(X_val, \n",
    "                                                     y_val, \n",
    "                                                     test_size=0.057414, \n",
    "                                                     random_state=124)\n",
    "\n",
    "\n",
    "print(X.shape,X_train.shape,X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb45ef20-cc09-4d8f-94ad-44fbf26dc7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#set up some intermediate saving callback\n",
    "checkpoint_filepath = 'best_comb.keras'\n",
    "\n",
    "model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='mean_absolute_percentage_error',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b7930a14-9ba7-45f4-98a7-c4494dea3fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Will use exponential learning rate decay\n",
    "initial_learning_rate = 1e-4\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.95,\n",
    "    staircase=False)\n",
    "\n",
    "callback = [model_checkpoint_callback]\n",
    "\n",
    "#Adam optimizer\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "#Network consists out of 9 layers, split in sets of 3, containing 100, 200, 300 neurons respectively.\n",
    "N0 = 8\n",
    "N1 = 100\n",
    "N2 = 200\n",
    "N3 = 300\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#input vector\n",
    "model.add(Input(shape=[3]))\n",
    "\n",
    "#Set 1\n",
    "model.add(Dense(N1, kernel_initializer=LecunNormal(seed=142),activation='relu'))\n",
    "model.add(Dense(N1, kernel_initializer=LecunNormal(seed=242),activation='relu'))\n",
    "model.add(Dense(N1, kernel_initializer=LecunNormal(seed=342),activation='relu'))\n",
    "\n",
    "#Set 2\n",
    "model.add(Dense(N2, kernel_initializer=LecunNormal(seed=442),activation='relu'))\n",
    "model.add(Dense(N2, kernel_initializer=LecunNormal(seed=542),activation='relu'))\n",
    "model.add(Dense(N2, kernel_initializer=LecunNormal(seed=642),activation='relu'))\n",
    "\n",
    "#Set 3\n",
    "model.add(Dense(N3, kernel_initializer=LecunNormal(seed=742),activation='relu'))\n",
    "model.add(Dense(N3, kernel_initializer=LecunNormal(seed=842),activation='relu'))\n",
    "model.add(Dense(N3, kernel_initializer=LecunNormal(seed=942),activation='relu'))\n",
    "\n",
    "#Output Layer\n",
    "model.add(Dense(N0,activation='linear'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=opt,metrics=['mean_absolute_error','mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25e49d-68ef-466a-8123-e5395aee8fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Time to learn, 1000 epochs, 2000 batchsize\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=1000,\n",
    "                    batch_size=2000, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=2,\n",
    "                    callbacks=[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7671538d-12d6-4312-a5d8-1b7a9b376c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we want to save the netork by using keras2cpp. https://github.com/gosha20777/keras2cpp\n",
    "from keras2cpp import export_model\n",
    "\n",
    "export_model(model, 'comb_final_compact_v2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6f3a9499-0dbc-460b-99a6-5416d5453513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#next do a test on the test set we kept aside\n",
    "predictions = model.predict(X_test,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f49ae3-eccc-4d45-97c9-432095e36ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get stats on training and validations\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "mae = history.history['mean_absolute_error']\n",
    "val_mae = history.history['val_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410d239-54ea-4775-a585-02ef0014d371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.semilogy(loss, label='Training loss')\n",
    "plt.semilogy(val_loss, label='Validation loss')\n",
    "plt.xlabel(\"Epoch\",fontsize=20)\n",
    "plt.ylabel(\"Loss\",fontsize=20)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663203f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Process the input and output data of the test set so we can compare things to the fit functions\n",
    "X1_test_unscaled = X_test[:,0]\n",
    "X2_test_unscaled = X_test[:,1] \n",
    "\n",
    "nu_test = np.power(10,X1_test_unscaled*xmax[0] + xmin[0])\n",
    "theta_e_test = np.power(10,X2_test_unscaled*xmax[1] + xmin[1])\n",
    "\n",
    "jI_predictions_unscaled = predictions[:,0] \n",
    "aI_predictions_unscaled=  predictions[:,1] \n",
    "\n",
    "jQ_predictions_unscaled = predictions[:,2]\n",
    "aQ_predictions_unscaled=  predictions[:,3]\n",
    "rQ_predictions_unscaled = predictions[:,4]\n",
    "\n",
    "jV_predictions_unscaled = predictions[:,5]\n",
    "aV_predictions_unscaled=  predictions[:,6]\n",
    "rV_predictions_unscaled = predictions[:,7]\n",
    "\n",
    "jI_truth_unscaled = y_test[:,0] \n",
    "aI_truth_unscaled = y_test[:,1] \n",
    "\n",
    "jQ_truth_unscaled = y_test[:,2] \n",
    "aQ_truth_unscaled = y_test[:,3] \n",
    "rQ_truth_unscaled = y_test[:,4] \n",
    "\n",
    "jV_truth_unscaled = y_test[:,5] \n",
    "aV_truth_unscaled = y_test[:,6] \n",
    "rV_truth_unscaled = y_test[:,7] \n",
    "\n",
    "jI_test = jI_predictions_unscaled\n",
    "aI_test = aI_predictions_unscaled\n",
    "\n",
    "jQ_test = jQ_predictions_unscaled\n",
    "aQ_test = aQ_predictions_unscaled\n",
    "rQ_test = rQ_predictions_unscaled\n",
    "\n",
    "jV_test = jV_predictions_unscaled\n",
    "aV_test = aV_predictions_unscaled\n",
    "rV_test = rV_predictions_unscaled\n",
    "\n",
    "jI_truth = jI_truth_unscaled\n",
    "aI_truth = aI_truth_unscaled\n",
    "\n",
    "jQ_truth = jQ_truth_unscaled\n",
    "aQ_truth = aQ_truth_unscaled\n",
    "rQ_truth = rQ_truth_unscaled\n",
    "\n",
    "jV_truth = jV_truth_unscaled\n",
    "aV_truth = aV_truth_unscaled\n",
    "rV_truth = rV_truth_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "42dd453e-d0ab-411c-ba76-1945591b5f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plotting function\n",
    "def plot_scatter(ax,data,truth,xlabel,ylabel,textlabel=0,mini=0,maxi=0,xticks=True,yticks=True):\n",
    "    ax.scatter(data,truth, s=1,c='gray')\n",
    "    if(mini!=maxi):\n",
    "        ax.set_xlim(mini,maxi)\n",
    "        ax.set_ylim(mini,maxi)\n",
    "    if(textlabel!=0):\n",
    "        plt.text(.01, .99, textlabel, ha='left', va='top', transform=ax.transAxes,fontsize=30)    \n",
    "    if(xticks):\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "    if(yticks):\n",
    "        ax.set_ylabel(ylabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4c5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot results Network vs ground truth\n",
    "\n",
    "N=8\n",
    "font = {'size'   : 25}\n",
    "print(jI_test.shape)\n",
    "matplotlib.rc('font', **font)\n",
    "plt.figure(figsize=(14,14),dpi=100)\n",
    "\n",
    "ax=plt.subplot(421)\n",
    "plot_scatter(ax,jI_test,jI_truth,\"Network\",\"Truth\",r\"$j_{\\rm I}$\",-1,1,xticks=False)\n",
    "ax=plt.subplot(422)\n",
    "plot_scatter(ax,aI_test,aI_truth,\"Network\",\"Truth\",r\"$\\alpha_{\\rm I}$\",-1,1,xticks=False,yticks=False)\n",
    "ax=plt.subplot(423)\n",
    "\n",
    "plot_scatter(ax,jQ_test,jQ_truth,\"Network\",\"Truth\",r\"$j_{\\rm Q}$\",-1,1,xticks=False)\n",
    "ax=plt.subplot(424)\n",
    "\n",
    "plot_scatter(ax,aQ_test,aQ_truth,\"Network\",\"Truth\",r\"$\\alpha_{\\rm Q}$\",-1,1,xticks=False,yticks=False)\n",
    "ax=plt.subplot(425)\n",
    "\n",
    "plot_scatter(ax,rQ_test,rQ_truth,\"Network\",\"Truth\",r\"$\\rho_{\\rm Q}$\",np.min(rQ_test),np.max(rQ_test),xticks=False)\n",
    "ax=plt.subplot(426)\n",
    "\n",
    "plot_scatter(ax,jV_test,jV_truth,\"Network\",\"Truth\",r\"$j_{\\rm V}$\",-1,1,xticks=False,yticks=False)\n",
    "ax=plt.subplot(427)\n",
    "\n",
    "plot_scatter(ax,aV_test,aV_truth,\"Network\",\"Truth\",r\"$\\alpha_{\\rm V}$\",-1,1,xticks=True)\n",
    "\n",
    "ax=plt.subplot(428)\n",
    "\n",
    "plot_scatter(ax,rV_test,rV_truth,\"Network\",\"Truth\",r\"$\\rho_{\\rm V}$\",np.min(rV_test),np.max(rV_test),xticks=True,yticks=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"trained.png\",dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f5d9e-e9d5-4795-adbd-4800c8c7eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results Fit function vs ground truth\n",
    "\n",
    "N=8\n",
    "font = {'size'   : 25}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "plt.figure(figsize=(14,14),dpi=100)\n",
    "\n",
    "ax=plt.subplot(421)\n",
    "y_fit = (np.log10(jI_fit) - ymin[0])/ymax[0]\n",
    "y_truth = (np.log10(jI)- ymin[0])/ymax[0]\n",
    "plot_scatter(ax,y_fit,y_truth,\"Fit\", \"Truth\",r\"$j_{\\rm I}$\",-1,1,xticks=False)\n",
    "\n",
    "ax=plt.subplot(422)\n",
    "y_fit = (np.log10(aI_fit)- ymin[1])/ymax[1]\n",
    "y_truth = (np.log10(aI)- ymin[1])/ymax[1]\n",
    "plot_scatter(ax,y_fit,y_truth,\"Fit\", \"Truth\",r\"$\\alpha_{\\rm I}$\",-1,1,xticks=False,yticks=False)\n",
    "\n",
    "ax=plt.subplot(423)\n",
    "y_fit = (np.log10(jQ_fit)- ymin[2])/ymax[2]\n",
    "y_truth = (np.log10(jQ)- ymin[2])/ymax[2]\n",
    "plot_scatter(ax,y_fit,y_truth,\"Fit\", \"Truth\",r\"$j_{\\rm Q}$\",-1,1,xticks=False)\n",
    "\n",
    "ax=plt.subplot(424)\n",
    "y_fit = (np.log10(aQ_fit)- ymin[3])/ymax[3]\n",
    "y_truth = (np.log10(aQ)- ymin[3])/ymax[3]\n",
    "plot_scatter(ax,y_fit,y_truth,\"Fit\", \"Truth\",r\"$\\alpha_{\\rm Q}$\",-1,1,xticks=False,yticks=False)\n",
    "\n",
    "ax=plt.subplot(425)\n",
    "plot_scatter(ax,-rQ_fit/6e-13,rQ/6e-13,\"Fit\", \"Truth\",r\"$\\rho_{\\rm Q}/6\\times10^{-13}$\",-1,0.1,xticks=False)\n",
    "\n",
    "ax=plt.subplot(426)\n",
    "y_fit = (np.log10(jV_fit)- ymin[5])/ymax[5]\n",
    "y_truth = (np.log10(jV)- ymin[5])/ymax[5]\n",
    "plot_scatter(ax,y_fit,y_truth ,\"Fit\", \"Truth\",r\"$j_{\\rm V}$\",-1,1,xticks=False,yticks=False)\n",
    "\n",
    "ax=plt.subplot(427)\n",
    "y_fit = (np.log10(aV_fit)- ymin[6])/ymax[6]\n",
    "y_truth = (np.log10(aV)- ymin[6])/ymax[6]\n",
    "plot_scatter(ax,y_fit,y_truth,\"Fit\", \"Truth\",r\"$\\alpha_{\\rm V}$\",-1,1,xticks=True)\n",
    "\n",
    "ax=plt.subplot(428)\n",
    "plot_scatter(ax,rV_fit/1e-12,rV/1e-12,\"Fit\", \"Truth\",r\"$\\rho_{\\rm V}/10^{-12}$\",-1,1,xticks=True,yticks=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"fit.png\",dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-gpu",
   "language": "python",
   "name": "jax-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
